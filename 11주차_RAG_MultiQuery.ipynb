{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMCUXZumr44t",
    "outputId": "894b5720-289f-4c02-98cb-d62639a358de"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-community\n",
    "# !pip install pymupdf\n",
    "# !pip install faiss-cpu\n",
    "# !pip install transformers\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225,
     "referenced_widgets": [
      "2c5cf6540e7c4e46af11dd304b40fe47",
      "ebdb4cec622544abbf2eb125fecfb71c",
      "ceddbdd35d1742058dadbe4b90885218",
      "8ceaeeb2f00e4b108b38ff7a79a49a4d",
      "744171bdbe3845b2a6e8016cde8adc0f",
      "86d9e877d3424948b3e6c231604c7f27",
      "1693dbef3ef24dfea6b05faf16e03d26",
      "65676d52efc14ff18d562d8675f7ef74",
      "6963f794c1b44bb09a677eaf0c0a0ccb",
      "842690b32670437091866a3c2515e02d",
      "8a9c715308054b48a4b241f1df00365b"
     ]
    },
    "id": "tRmDb7c1aPY8",
    "outputId": "5feb45e4-d02f-4a3f-ffcf-59344c42b6c5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n",
      "Fetching 4 files: 100%|██████████| 4/4 [07:21<00:00, 110.48s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.26it/s]\n",
      "Device set to use cuda:0\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "/tmp/ipykernel_283/3956875414.py:62: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "import torch  # 추가: GPU 메모리 관리 및 디바이스 설정\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "loader = PyMuPDFLoader(\"SPRi AI Brief 5월호 산업동향.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BM-K/KoSimCSE-roberta-multitask\",\n",
    "    model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}  # 추가: 디바이스 자동 설정\n",
    ")\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata={\"hnsw:construction_ef\": 100},\n",
    ")\n",
    "\n",
    "# 단계 5: Multi-Query Retriever 설정\n",
    "# 변경: MultiQueryRetriever를 사용하여 다중 질문을 기반으로 문서 검색\n",
    "multi_query_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"당신은 질문 생성자입니다.\n",
    "    사용자의 질문과 관련된 다양한 관점의 질문을 한국어로 5개만 생성하세요.\n",
    "    질문은 원래 질문과 의미가 유사해야 하며, 문서에서 관련 정보를 더 잘 검색할 수 있도록 재구성해야 합니다.\n",
    "    각 질문은 번호를 붙여 구분하세요:\n",
    "\n",
    "    원래 질문: {question}\"\"\"\n",
    ")\n",
    "\n",
    "model_name = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,  # 추가: 패딩 토큰 ID 설정\n",
    "    do_sample=False,\n",
    "    temperature=0.0,\n",
    "    return_full_text=False\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# 변경: MultiQueryRetriever 초기화\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",  # 추가: 유사도 기반 검색 명시\n",
    "        search_kwargs={\"k\": 4}  # 추가: 상위 4개 문서 반환\n",
    "    ),\n",
    "    llm=llm,\n",
    "    prompt=multi_query_prompt\n",
    ")\n",
    "\n",
    "# 추가: 답변 생성을 위한 프롬프트\n",
    "answer_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"당신은 주어진 컨텍스트를 기반으로 질문에 답변하는 AI 어시스턴트입니다.\n",
    "    답변은 간결하고 정확해야 하며, 한국어로 작성하세요.\n",
    "    컨텍스트에 없는 정보는 사용하지 마세요. 정보가 없으면 \"컨텍스트에 관련 정보가 없습니다.\"라고 답변하세요.\n",
    "\n",
    "    #Context:\n",
    "    {context}\n",
    "\n",
    "    #Question:\n",
    "    {question}\n",
    "\n",
    "    #Answer:\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# 변경: 디버깅용 체인 수정, 5개 질문만 출력하도록 설정\n",
    "def parse_questions(output):\n",
    "    # 출력에서 질문만 추출 (번호가 붙은 5개 질문)\n",
    "    lines = output.strip().split(\"\\n\")\n",
    "    questions = [line for line in lines if line.strip().startswith((\"1.\", \"2.\", \"3.\", \"4.\", \"5.\"))]\n",
    "    return \"\\n\".join(questions[:4])  # 최대 4개 질문 반환\n",
    "\n",
    "custom_multiquery_chain = (\n",
    "    {\"question\": RunnablePassthrough()} \n",
    "    | multi_query_prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    "    | parse_questions  # 추가: 질문 파싱 함수로 5개 질문만 출력\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "ITi_dtbv3W2X",
    "outputId": "fdde919c-4e59-414d-9238-08344f403038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.\\n    1.1. AI 산업의 현재 상태는 어떻습니까?\\n    1.2. AI 산업의 미래는 어떻습니까?\\n    1.3. AI 산업의 발전 방향은 무엇입니까?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'AI 산업동향은 어때?'\n",
    "multi_queries = custom_multiquery_chain.invoke(question)\n",
    "multi_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1693dbef3ef24dfea6b05faf16e03d26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c5cf6540e7c4e46af11dd304b40fe47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ebdb4cec622544abbf2eb125fecfb71c",
       "IPY_MODEL_ceddbdd35d1742058dadbe4b90885218",
       "IPY_MODEL_8ceaeeb2f00e4b108b38ff7a79a49a4d"
      ],
      "layout": "IPY_MODEL_744171bdbe3845b2a6e8016cde8adc0f"
     }
    },
    "65676d52efc14ff18d562d8675f7ef74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6963f794c1b44bb09a677eaf0c0a0ccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "744171bdbe3845b2a6e8016cde8adc0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "842690b32670437091866a3c2515e02d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86d9e877d3424948b3e6c231604c7f27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a9c715308054b48a4b241f1df00365b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ceaeeb2f00e4b108b38ff7a79a49a4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_842690b32670437091866a3c2515e02d",
      "placeholder": "​",
      "style": "IPY_MODEL_8a9c715308054b48a4b241f1df00365b",
      "value": " 4/4 [00:17&lt;00:00,  3.72s/it]"
     }
    },
    "ceddbdd35d1742058dadbe4b90885218": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65676d52efc14ff18d562d8675f7ef74",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6963f794c1b44bb09a677eaf0c0a0ccb",
      "value": 4
     }
    },
    "ebdb4cec622544abbf2eb125fecfb71c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86d9e877d3424948b3e6c231604c7f27",
      "placeholder": "​",
      "style": "IPY_MODEL_1693dbef3ef24dfea6b05faf16e03d26",
      "value": "Loading checkpoint shards: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
