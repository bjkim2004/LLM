{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "85OwZN_6UIXF",
    "outputId": "a4900672-667c-4f51-c67c-613336d4e0ec"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # CUDA major, minor 버전 확인\n",
    "# major_version, minor_version = torch.cuda.get_device_capability()\n",
    "# major_version, minor_version\n",
    "\n",
    "# # unsloth 설치\n",
    "# !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# if major_version >= 8:\n",
    "#     # 새로운 GPU(예: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)에 사용\n",
    "#     !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "# else:\n",
    "#     # 오래된 GPU(예: V100, Tesla T4, RTX 20xx)에 사용하세요.\n",
    "#     !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N_74YE8-W7_r",
    "outputId": "cf8eb081-5d08-470b-a5b2-e76c1e4b29d3"
   },
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install langchain\n",
    "# !pip install langchain-community\n",
    "# !pip install pymupdf\n",
    "# !pip install chromadb\n",
    "# !pip install transformers\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Chroma \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# 단계 1: 문서 로드(Load Documents)\n",
    "PDF_FILE_PATH = \"SPRi AI Brief 5월호 산업동향.pdf\"\n",
    "try:\n",
    "    loader = PyMuPDFLoader(PDF_FILE_PATH)\n",
    "    docs = loader.load()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF: {e}\")\n",
    "    print(f\"Please ensure the PDF file is available at '{PDF_FILE_PATH}' or provide a direct downloadable URL.\")\n",
    "    docs = [] \n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# 단계 3: 임베딩(Embedding) 생성\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BM-K/KoSimCSE-roberta-multitask\"\n",
    ")\n",
    "\n",
    "# 단계 4: DB 생성(Create DB) 및 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata={\"hnsw:construction_ef\": 500, \"hnsw:M\": 32},\n",
    ")\n",
    "\n",
    "# 단계 5: 검색기(Retriever) 생성\n",
    "# 변경: CrossEncoderReranker에서 top_k 제거, ContextualCompressionRetriever에서 k=3 설정\n",
    "base_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        'k': 10,\n",
    "        'fetch_k': 20,\n",
    "        'score_threshold': 0.6\n",
    "    }\n",
    ")\n",
    "cross_encoder = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
    "reranker = CrossEncoderReranker(model=cross_encoder)  # 변경: top_k=3 제거\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=base_retriever,\n",
    "    search_kwargs={\"k\": 3}  # 추가: 상위 3개 문서 반환 설정\n",
    ")\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "system_prompt_text = \"\"\"당신은 주어진 컨텍스트를 기반으로 질문에 답변하는 AI 어시스턴트입니다.\n",
    "답변은 간결하고 정확해야 하며, 한국어로 작성하세요.\n",
    "컨텍스트에 없는 정보는 절대로 사용하지 말고, 만약 컨텍스트에 답변이 없다면 \"컨텍스트에서 답변을 찾을 수 없습니다.\"라고 솔직하게 답변하세요.\"\"\"\n",
    "\n",
    "llama3_prompt_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id>\n",
    "\n",
    "{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id>\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=llama3_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"system_prompt\": system_prompt_text}\n",
    ")\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "model_name = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model {model_name}: {e}\")\n",
    "    raise e\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,\n",
    "     max_new_tokens=256,  # 변경: 256 -> 1024로 증가하여 더 긴 답변 생성\n",
    "    repetition_penalty=1.2,  # 추가: 긴 답변에서 반복 억제 강화\n",
    "    top_p=0.95  # 변경: 0.9 -> 0.95로 조정하여 긴 답변에서도 다양성 유지\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KW0TwA_DayXx",
    "outputId": "b205d78a-733a-4944-9ce4-d75a2e4f83ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU 집행위원회는 'InvestAI' 이니셔티브를 통해 AI에 총 2,000억 유로를 투자했습니다. 또한, AI 대륙 행동계획에서는 AI 컴퓨팅 인프라 구축, 데이터 접근성 확대, 전략적 영역의 AI 촉진, AI 역량과 인재 육성, AI 법 시행 간소화 등의 5가지 주요 과제를 제시하여 AI 리더십을 강조합니다. AI 대륙 행동계획에는 AI 컴퓨팅 인프라 구축을 위하여 200억 유로를 투자하겠다고 밝혔다. 더불어, EU 내 데이터센터 용량을 최소 3배 확대하고, 데이터 센터 관련 허가 절차 간소화 등을 통해서 클라우드와 데이터센터 투자 활성을 장려할 방침입니다.󰏽️🤝‍♀️😊️💬️👍️🎯️🚫️🕒️📈️🛠️👸️👋️👂️👆️👇️👅️�\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"EU집행위원회는 AI에 얼마를 투자했지?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0214d43c536c4b9bb2202d00d83dfca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "119d9aafef6443c2aa2a36fb5efd5225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f6eacac42b449d9bd2b6afb8fe3f796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b14bfd5a3d44b1595419adfd1c1b5b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79c9e0e54a7f46779f29a6c8b5134c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5ea541fa65a46d59fbb6f686ba3707f",
      "placeholder": "​",
      "style": "IPY_MODEL_4b14bfd5a3d44b1595419adfd1c1b5b5",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "79d1aedcb4164c57a37bdd651324e990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_119d9aafef6443c2aa2a36fb5efd5225",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0214d43c536c4b9bb2202d00d83dfca6",
      "value": 4
     }
    },
    "8b264b7bef6a487197a760282c956a80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5ea541fa65a46d59fbb6f686ba3707f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b83bf96e75eb452b98d0444d747a3b87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba5d781319c545c3b43d7ed59f884a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79c9e0e54a7f46779f29a6c8b5134c4e",
       "IPY_MODEL_79d1aedcb4164c57a37bdd651324e990",
       "IPY_MODEL_fcee4d3fc2fe4ca1b5a88c9bec30fa5c"
      ],
      "layout": "IPY_MODEL_b83bf96e75eb452b98d0444d747a3b87"
     }
    },
    "fcee4d3fc2fe4ca1b5a88c9bec30fa5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b264b7bef6a487197a760282c956a80",
      "placeholder": "​",
      "style": "IPY_MODEL_3f6eacac42b449d9bd2b6afb8fe3f796",
      "value": " 4/4 [00:17&lt;00:00,  3.66s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
