{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "85OwZN_6UIXF",
    "outputId": "a4900672-667c-4f51-c67c-613336d4e0ec"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # CUDA major, minor ë²„ì „ í™•ì¸\n",
    "# major_version, minor_version = torch.cuda.get_device_capability()\n",
    "# major_version, minor_version\n",
    "\n",
    "# # unsloth ì„¤ì¹˜\n",
    "# !pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# if major_version >= 8:\n",
    "#     # ìƒˆë¡œìš´ GPU(ì˜ˆ: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)ì— ì‚¬ìš©\n",
    "#     !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "# else:\n",
    "#     # ì˜¤ë˜ëœ GPU(ì˜ˆ: V100, Tesla T4, RTX 20xx)ì— ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "#     !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N_74YE8-W7_r",
    "outputId": "cf8eb081-5d08-470b-a5b2-e76c1e4b29d3"
   },
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install langchain\n",
    "# !pip install langchain-community\n",
    "# !pip install pymupdf\n",
    "# !pip install chromadb\n",
    "# !pip install transformers\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00,  1.41it/s]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Chroma \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "# ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)\n",
    "PDF_FILE_PATH = \"SPRi AI Brief 5ì›”í˜¸ ì‚°ì—…ë™í–¥.pdf\"\n",
    "try:\n",
    "    loader = PyMuPDFLoader(PDF_FILE_PATH)\n",
    "    docs = loader.load()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDF: {e}\")\n",
    "    print(f\"Please ensure the PDF file is available at '{PDF_FILE_PATH}' or provide a direct downloadable URL.\")\n",
    "    docs = [] \n",
    "\n",
    "# ë‹¨ê³„ 2: ë¬¸ì„œ ë¶„í• (Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BM-K/KoSimCSE-roberta-multitask\"\n",
    ")\n",
    "\n",
    "# ë‹¨ê³„ 4: DB ìƒì„±(Create DB) ë° ì €ì¥\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=split_documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_metadata={\"hnsw:construction_ef\": 500, \"hnsw:M\": 32},\n",
    ")\n",
    "\n",
    "# ë‹¨ê³„ 5: ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "# ë³€ê²½: CrossEncoderRerankerì—ì„œ top_k ì œê±°, ContextualCompressionRetrieverì—ì„œ k=3 ì„¤ì •\n",
    "base_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        'k': 10,\n",
    "        'fetch_k': 20,\n",
    "        'score_threshold': 0.6\n",
    "    }\n",
    ")\n",
    "cross_encoder = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
    "reranker = CrossEncoderReranker(model=cross_encoder)  # ë³€ê²½: top_k=3 ì œê±°\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=base_retriever,\n",
    "    search_kwargs={\"k\": 3}  # ì¶”ê°€: ìƒìœ„ 3ê°œ ë¬¸ì„œ ë°˜í™˜ ì„¤ì •\n",
    ")\n",
    "\n",
    "# ë‹¨ê³„ 6: í”„ë¡¬í”„íŠ¸ ìƒì„±(Create Prompt)\n",
    "system_prompt_text = \"\"\"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "ë‹µë³€ì€ ê°„ê²°í•˜ê³  ì •í™•í•´ì•¼ í•˜ë©°, í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ ë§ê³ , ë§Œì•½ ì»¨í…ìŠ¤íŠ¸ì— ë‹µë³€ì´ ì—†ë‹¤ë©´ \"ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\"\"\"\n",
    "\n",
    "llama3_prompt_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id>\n",
    "\n",
    "{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id>\n",
    "\n",
    "#Context:\n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=llama3_prompt_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"system_prompt\": system_prompt_text}\n",
    ")\n",
    "\n",
    "# ë‹¨ê³„ 7: ì–¸ì–´ëª¨ë¸(LLM) ìƒì„±\n",
    "model_name = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model {model_name}: {e}\")\n",
    "    raise e\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,\n",
    "     max_new_tokens=256,  # ë³€ê²½: 256 -> 1024ë¡œ ì¦ê°€í•˜ì—¬ ë” ê¸´ ë‹µë³€ ìƒì„±\n",
    "    repetition_penalty=1.2,  # ì¶”ê°€: ê¸´ ë‹µë³€ì—ì„œ ë°˜ë³µ ì–µì œ ê°•í™”\n",
    "    top_p=0.95  # ë³€ê²½: 0.9 -> 0.95ë¡œ ì¡°ì •í•˜ì—¬ ê¸´ ë‹µë³€ì—ì„œë„ ë‹¤ì–‘ì„± ìœ ì§€\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# ë‹¨ê³„ 8: ì²´ì¸(Chain) ìƒì„±\n",
    "chain = (\n",
    "    {\"context\": retriever | RunnableLambda(format_docs), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KW0TwA_DayXx",
    "outputId": "b205d78a-733a-4944-9ce4-d75a2e4f83ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU ì§‘í–‰ìœ„ì›íšŒëŠ” 'InvestAI' ì´ë‹ˆì…”í‹°ë¸Œë¥¼ í†µí•´ AIì— ì´ 2,000ì–µ ìœ ë¡œë¥¼ íˆ¬ìí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, AI ëŒ€ë¥™ í–‰ë™ê³„íšì—ì„œëŠ” AI ì»´í“¨íŒ… ì¸í”„ë¼ êµ¬ì¶•, ë°ì´í„° ì ‘ê·¼ì„± í™•ëŒ€, ì „ëµì  ì˜ì—­ì˜ AI ì´‰ì§„, AI ì—­ëŸ‰ê³¼ ì¸ì¬ ìœ¡ì„±, AI ë²• ì‹œí–‰ ê°„ì†Œí™” ë“±ì˜ 5ê°€ì§€ ì£¼ìš” ê³¼ì œë¥¼ ì œì‹œí•˜ì—¬ AI ë¦¬ë”ì‹­ì„ ê°•ì¡°í•©ë‹ˆë‹¤. AI ëŒ€ë¥™ í–‰ë™ê³„íšì—ëŠ” AI ì»´í“¨íŒ… ì¸í”„ë¼ êµ¬ì¶•ì„ ìœ„í•˜ì—¬ 200ì–µ ìœ ë¡œë¥¼ íˆ¬ìí•˜ê² ë‹¤ê³  ë°í˜”ë‹¤. ë”ë¶ˆì–´, EU ë‚´ ë°ì´í„°ì„¼í„° ìš©ëŸ‰ì„ ìµœì†Œ 3ë°° í™•ëŒ€í•˜ê³ , ë°ì´í„° ì„¼í„° ê´€ë ¨ í—ˆê°€ ì ˆì°¨ ê°„ì†Œí™” ë“±ì„ í†µí•´ì„œ í´ë¼ìš°ë“œì™€ ë°ì´í„°ì„¼í„° íˆ¬ì í™œì„±ì„ ì¥ë ¤í•  ë°©ì¹¨ì…ë‹ˆë‹¤.ó°½ï¸ğŸ¤â€â™€ï¸ğŸ˜Šï¸ğŸ’¬ï¸ğŸ‘ï¸ğŸ¯ï¸ğŸš«ï¸ğŸ•’ï¸ğŸ“ˆï¸ğŸ› ï¸ğŸ‘¸ï¸ğŸ‘‹ï¸ğŸ‘‚ï¸ğŸ‘†ï¸ğŸ‘‡ï¸ğŸ‘…ï¸ï¿½\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ì‹¤í–‰(Run Chain)\n",
    "# ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜ë¥¼ ì…ë ¥í•˜ê³ , ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "question = \"EUì§‘í–‰ìœ„ì›íšŒëŠ” AIì— ì–¼ë§ˆë¥¼ íˆ¬ìí–ˆì§€?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf chroma_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0214d43c536c4b9bb2202d00d83dfca6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "119d9aafef6443c2aa2a36fb5efd5225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f6eacac42b449d9bd2b6afb8fe3f796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b14bfd5a3d44b1595419adfd1c1b5b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79c9e0e54a7f46779f29a6c8b5134c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5ea541fa65a46d59fbb6f686ba3707f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4b14bfd5a3d44b1595419adfd1c1b5b5",
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    },
    "79d1aedcb4164c57a37bdd651324e990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_119d9aafef6443c2aa2a36fb5efd5225",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0214d43c536c4b9bb2202d00d83dfca6",
      "value": 4
     }
    },
    "8b264b7bef6a487197a760282c956a80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5ea541fa65a46d59fbb6f686ba3707f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b83bf96e75eb452b98d0444d747a3b87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba5d781319c545c3b43d7ed59f884a07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79c9e0e54a7f46779f29a6c8b5134c4e",
       "IPY_MODEL_79d1aedcb4164c57a37bdd651324e990",
       "IPY_MODEL_fcee4d3fc2fe4ca1b5a88c9bec30fa5c"
      ],
      "layout": "IPY_MODEL_b83bf96e75eb452b98d0444d747a3b87"
     }
    },
    "fcee4d3fc2fe4ca1b5a88c9bec30fa5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b264b7bef6a487197a760282c956a80",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3f6eacac42b449d9bd2b6afb8fe3f796",
      "value": "â€‡4/4â€‡[00:17&lt;00:00,â€‡â€‡3.66s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
