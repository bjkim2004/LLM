{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "85OwZN_6UIXF",
        "outputId": "f833591a-0619-49fb-dc21-56851a54b9dc",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-92re6uxy/unsloth_95ed79c3cf954a9d84c69bcc5a664d61\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-92re6uxy/unsloth_95ed79c3cf954a9d84c69bcc5a664d61\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 937f684d4377c465452a7723c8bb97f1ecd2a3d5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unsloth_zoo>=2025.5.7 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading unsloth_zoo-2025.5.7-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
            "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.9.20-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,==4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.51.3)\n",
            "Collecting datasets>=3.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Collecting protobuf<4.0.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.31.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
            "Collecting bitsandbytes>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.13.2)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.5.7->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.5.7-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.20-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2025.5.5-py3-none-any.whl size=265245 sha256=e158846b45e09b92b94ca46bba01f53117dda49144cd0e310102ec1044f68db2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3w2ucgau/wheels/d1/17/05/850ab10c33284a4763b0595cd8ea9d01fce6e221cac24b3c01\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth, shtab, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 datasets-3.6.0 fsspec-2025.3.0 msgspec-0.19.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-3.20.3 shtab-1.7.2 trl-0.15.2 tyro-0.9.20 unsloth-2025.5.5 unsloth_zoo-2025.5.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "05b13cc3b1bf45ada12779f80f08f54c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xformers\n",
            "  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: xformers, ninja, flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1 ninja-1.11.1.4 xformers-0.0.30\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# CUDA major, minor 버전 확인\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "major_version, minor_version\n",
        "\n",
        "# unsloth 설치\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 8:\n",
        "    # 새로운 GPU(예: Ampere, Hopper GPUs - RTX 30xx, RTX 40xx, A100, H100, L40)에 사용\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "    # 오래된 GPU(예: V100, Tesla T4, RTX 20xx)에 사용하세요.\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install pymupdf\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "N_74YE8-W7_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c058822-b097-442a-c0c5-3f84fadd1da1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "# 단계 1: 문서 로드(Load Documents)\n",
        "loader = PyMuPDFLoader(\"SPRi AI Brief 5월호 산업동향.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "# 단계 2: 문서 분할(Split Documents)\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "\n",
        "# 단계 3: 임베딩(Embedding) 생성\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"BM-K/KoSimCSE-roberta-multitask\"\n",
        "        # model_name = 'jhgan/ko-sroberta-nli'\n",
        "    )\n",
        "\n",
        "# 단계 4: DB 생성(Create DB) 및 저장\n",
        "# 벡터스토어를 생성합니다.\n",
        "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
        "\n",
        "# 단계 5: 검색기(Retriever) 생성\n",
        "# 문서에 포함되어 있는 정보를 검색하고 생성합니다.\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# 단계 6: 프롬프트 생성(Create Prompt)\n",
        "# 프롬프트를 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"다음 컨텍스트를 사용하여 질문에 답변하세요.\n",
        "    답변은 간결하고 정확해야 하며, 한국어로 작성하세요.\n",
        "    컨텍스트에 없는 정보는 사용하지 마세요.\n",
        "\n",
        "#Context:\n",
        "{context}\n",
        "\n",
        "#Question:\n",
        "{question}\n",
        "\n",
        "#Answer:\"\"\"\n",
        ")\n",
        "\n",
        "# 단계 7: 언어모델(LLM) 생성\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    # model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    model_name=\"beomi/Llama-3-Open-Ko-8B-Instruct-preview\",  # 모델명 설정\n",
        "    max_seq_length=16384,  # 최대 시퀀스 길이 설정\n",
        "    dtype=None,  # 데이터 타입을 설정\n",
        "    load_in_4bit=True,  # 4bit 양자화 로드 여부 설정\n",
        ")\n",
        "# model_name = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "llm_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=128,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        "    # device=0,  # CPU 사용, GPU 사용 시 0 또는 적절한 디바이스 ID\n",
        ")\n",
        "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "\n",
        "# 단계 8: 체인(Chain) 생성\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRmDb7c1aPY8",
        "outputId": "256cb784-a73d-4591-99ba-e57fac6be5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 체인 실행(Run Chain)\n",
        "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
        "question = \"EU집행위원회는 AI에 얼마를 투자했지?\"\n",
        "response = chain.invoke(question)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW0TwA_DayXx",
        "outputId": "b204e4d2-6a9b-466b-f8f1-9df657e18c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 컨텍스트에서 질문에 대한 답변을 찾아 1문장의 한국어로 작성하세요.\n",
            "컨텍스트에 없는 정보는 사용하지 마세요.\n",
            "\n",
            "#Context:\n",
            "[Document(id='ca8e0293-d2e4-4c9f-a9a5-0a08408d5328', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 4}, page_content='정책･법제\\n기업･산업\\n기술･연구\\n인력･교육\\n3\\nEU 집행위원회, EU의 AI 리더십을 위한 AI 대륙 행동계획 발표\\nn EU 집행위원회가 EU의 AI 리더십을 확보하기 위한 ‘AI 대륙 행동계획’을 수립하고 \\n‘InvestAI’ 이니셔티브를 통해 AI에 총 2,000억 유로를 투자할 계획\\nn AI 대륙 행동계획은 △AI 컴퓨팅 인프라 구축 △데이터 접근성 확대 △전략적 영역의 AI 촉진 \\n△AI 역량과 인재 육성 △AI 법 시행 간소화의 5개 영역을 중점 추진\\nKEY Contents\\n£ AI 대륙 행동계획, 컴퓨팅 인프라와 데이터 접근성 확보 및 AI 도입 확대를 추진\\nn EU 집행위원회가 2025년 4월 9일 EU의 AI 리더십을 확보하기 위해 중점 추진할 5개 핵심 영역을 \\n제시한 ‘AI 대륙 행동계획(AI Continent Action Plan)’을 발표\\n∙EU 집행위원회는 2025년 2월 발표한 ‘InvestAI’ 이니셔티브를 통해 AI에 총 2,000억 유로, 이중 AI'), Document(id='3e779491-dd80-4365-a326-6ed8b747d4af', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 4}, page_content='기가팩토리에 200억 유로를 투자해 행동계획을 뒷받침할 계획 \\nn (AI 컴퓨팅 인프라 구축) 유럽 전역에 AI 팩토리와 AI 기가팩토리를 구축하고 클라우드와 데이터센터에 \\n대한 민간 투자를 활성화\\n∙유럽 전역에 스타트업과 산업계, 연구자의 첨단 AI 모델과 애플리케이션 개발을 지원할 최소 13개의 AI \\n팩토리 및 대규모 컴퓨팅 파워와 데이터센터를 갖춘 최대 5개의 AI 기가팩토리를 구축\\n∙「EU 클라우드 및 AI 개발법(EU Cloud and AI Development Act)」* 입법으로 민간 투자를 촉진해 \\n5~7년 내 EU 내 데이터센터 용량을 최소 3배 확대\\n* EU 내 데이터센터 관련 허가 절차 간소화 등 클라우드와 데이터센터 투자 활성화를 위한 법안\\nn (데이터 접근성 확대) ‘데이터 연합(Data Union)’ 전략을 수립하고 AI 팩토리 내 ‘데이터 랩(Data \\nLab)’을 활용해 EU 단일 데이터 시장을 조성'), Document(id='770670b3-9b47-4b90-a37a-1a5041bd7e5d', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 1}, page_content='SPRi AI Brief\\n2025년 5월호\\n2\\nCONTENTS\\n정책･법제\\n∙미국 백악관 예산관리국, 연방정부의 AI 활용 및 조달 관련 지침 2종 공개\\n2\\n∙EU 집행위원회, EU의 AI 리더십을 위한 AI 대륙 행동계획 발표\\n3\\n∙아프리카 AI 정상회의, AI 아프리카 선언 발표\\n4\\n∙미국 하원 중국특별위원회, 딥시크에 의한 국가안보 위협 제기\\n5\\n∙중국 정부, AI 중심의 디지털 교육 활성화 정책 지침 발표\\n6\\n기업･산업\\n∙마이크로소프트·오픈AI·AWS 등 주요 기업, 앤스로픽의 MCP 프로토콜 채택\\n8\\n∙구글, AI 에이전트 간 통신 프로토콜 ‘A2A’ 공개 및 MCP 지원 발표\\n9\\n∙메타, 멀티모달 AI 모델 ‘라마 4’ 제품군 공개 및 성능 조작 의혹 부인\\n10\\n∙아마존, AI 에이전트 구축을 위한 AI 모델 ‘노바 액트’ 공개\\n11\\n∙오픈AI, GPT-4.1 API로 출시 및 o3와 o4-미니 출시 \\n12\\n∙샤오미 전기차 사망사고로 중국에서 자율주행 기능에 대한 우려 증대'), Document(id='76e05de3-2682-4e23-ad21-f848876385c3', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 4}, page_content='n (AI 역량과 인재 육성) 증가하는 AI 인재 수요에 대응해 EU 외부의 AI 인재 유치를 확대하고, AI 역량 교육과 훈련을 \\n위한 원스톱 교육기관으로 ‘AI 스킬 아카데미(AI Skills Academy)’를 출범해 EU 전역에서 AI 기술 격차를 해소 \\nn (AI 법 시행 간소화) ‘AI 법 서비스 데스크’를 개설하여 기업들에게 준법 관련 정보를 제공하고, AI 법 \\n시행을 지원할 지침과 실행 강령을 개발\\n출처 | European Commission, Shaping Europe’s leadership in artificial intelligence with the AI continent action plan, 2025.04.09.')]\n",
            "\n",
            "#Question:\n",
            "EU집행위원회는 AI에 얼마를 투자했지?\n",
            "\n",
            "#Answer: 2,000억 유로를 투자했습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 컴퓨팅 인프라 구축, 데이터 접근성 확대, 전략적 영역의 AI 촉진, AI 역량과 인재 육성을 추진하고 있습니다. 2025년 5월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 5월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙 행동계획’에 따라 AI 인재 육성, AI 법 시행 간소화를 추진하고 있습니다. 2025년 4월에 발표한 ‘AI 대륙\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"구글이 발표한 에이전트 간 상호운용성을 보장하기 위한 개방형 통신 프로토콜은?\"\n",
        "response = chain.invoke(question)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwYA9vk_dviR",
        "outputId": "bb294d5f-599d-42b5-8124-e47fe738ccf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 컨텍스트에서 질문에 대한 가장 핵심적인 답변을 찾으세요.\n",
            "답변은 간결하고 정확하게 한국어로 작성하세요.\n",
            "동일한 문장이나 내용을 절대 반복하지 마세요. 답변은 한 번만 명확하게 제시해야 합니다.\n",
            "컨텍스트에 없는 정보는 사용하지 마세요.\n",
            "\n",
            "#Context:\n",
            "[Document(id='a8d64211-3fe4-424e-a8aa-7a41d156cdc6', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 10}, page_content='정책･법제\\n기업･산업\\n기술･연구\\n인력･교육\\n9\\n구글, AI 에이전트 간 통신 프로토콜 ‘A2A’ 공개 및 MCP 지원 발표\\nn 구글이 에이전트 간 상호운용성을 보장하기 위한 개방형 통신 프로토콜 A2A를 공개했으며, \\nA2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원\\nn 구글은 제미나이 모델과 SDK에서 앤스로픽의 MCP 지원을 추가하기로 했으며, A2A가 MCP보다 \\n상위 계층의 프로토콜로서 MCP를 보완한다고 설명\\nKEY Contents\\n£ A2A, 다중 에이전트 간 협업을 위한 개방형 프로토콜로 설계\\nn 구글(Google)이 2025년 4월 9일 50개 이상의 기업*과 협력해 AI 에이전트 간 통신을 위한 개방형 \\n프로토콜 ‘A2A(Agent2Agent)’를 공개\\n* 액센추어(Accenture), 코히어(Cohere), 랭체인(Langchain), 페이팔(Paypal), 세일즈포스(Salesforce) 등'), Document(id='9649b8a4-fc1f-48d1-a3d7-10da8b230f2c', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 10}, page_content='∙구글은 다양한 플랫폼과 클라우드 환경에서 다중 AI 에이전트가 서로 통신하고 안전하게 정보를 교환하며 \\n작업을 조정할 수 있도록 A2A 프로토콜을 출시했다고 발표\\n∙구글에 따르면 A2A는 AI 에이전트 간 협업을 위한 표준 방식을 제공하기 위해 HTTP, SSE, JSON-RPC \\n등 기존 표준을 기반으로 구축되었으며, 기업 환경에서 요구하는 높은 수준의 인증 및 권한 관리 기능을 \\n제공하고 빠른 작업뿐 아니라 장시간 작업 환경에도 적합하며, 텍스트와 오디오, 동영상 스트리밍도 지원\\nn A2A는 작업을 구성하고 전달하는 역할을 하는 클라이언트 에이전트(Client Agent)와 작업을 수행하는 \\n원격 에이전트(Remote Agent) 간 원활한 통신을 위해 다음과 같은 기능을 제공\\n∙(기능 탐색) 각 에이전트가 자신의 기능을 JSON* 형식의 ‘에이전트 카드**’를 통해 공개하면 클라이언트 \\n에이전트는 작업 수행에 가장 적합한 에이전트를 식별해 A2A로 원격 에이전트와 통신'), Document(id='a50a7bc8-e17f-49ee-bb5e-1a5be4de4e9e', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 10}, page_content='4월 9일 X를 통해 구글이 앤스로픽의 MCP를 제미나이 모델과 SDK에서 지원하겠다고 발표*\\n*  https://x.com/demishassabis/status/1910107859041271977\\n∙구글에 따르면 A2A는 MCP를 보완하는 역할로서, MCP가 LLM을 데이터, 리소스 및 도구와 연결하는 \\n프로토콜이라면 A2A는 에이전트 간 협업을 위한 상위 수준의 프로토콜에 해당 \\n출처 | Google, Announcing the Agent2Agent Protocol (A2A), 2025.04.09.'), Document(id='82d07fd6-f0c8-429b-b696-c117b1d82e8b', metadata={'producer': 'Hancom PDF 1.3.0.505', 'creator': 'Hancom PDF 1.3.0.505', 'creationdate': '2025-05-09T09:07:04+09:00', 'source': 'SPRi AI Brief 5월호 산업동향.pdf', 'file_path': 'SPRi AI Brief 5월호 산업동향.pdf', 'total_pages': 28, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2025-05-09T09:07:04+09:00', 'trapped': '', 'modDate': \"D:20250509090704+09'00'\", 'creationDate': \"D:20250509090704+09'00'\", 'page': 10}, page_content='에이전트는 작업 수행에 가장 적합한 에이전트를 식별해 A2A로 원격 에이전트와 통신\\n* 키-값 쌍으로 이루어진 데이터 객체를 표현하기 위한 텍스트 기반의 개방형 표준 형식\\n** 에이전트의 기능과 스킬, 인증 요구사항 등을 설명하는 공개 메타데이터 파일\\n∙(작업 관리) 클라이언트 에이전트와 원격 에이전트는 최종 사용자의 요청에 대응해 작업 수명주기 전반에서 \\n작업 처리 상태를 지속 동기화하여 처리\\n∙(협업) 각 에이전트는 서로 컨텍스트, 응답, 작업 결과물, 사용자 지시와 같은 메시지를 교환해 협업을 진행\\n∙(사용자 경험 협의) 각 메시지에는 이미지, 동영상, 웹 양식과 같은 특정 콘텐츠 유형이 명시되어 있어, 각 \\n에이전트는 사용자 인터페이스(UI)에 맞게 적절한 콘텐츠 형식을 협의\\n£ 구글, 제미나이 모델과 SDK에서 앤스로픽의 MCP 지원 발표\\nn 한편, 구글 딥마인드(Google Deepmind)의 데미스 하사비스(Demis Hassabis) CEO는 2025년')]\n",
            "\n",
            "#Question:\n",
            "구글이 발표한 에이전트 간 상호운용성을 보장하기 위한 개방형 통신 프로토콜은?\n",
            "\n",
            "#Answer: \n",
            "A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통조 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개방형 통신 프로토콜입니다. A2A는 에이전트 간 기능 탐색, 작업 관리, 협업, 사용자 경험 협의 등의 다양한 기능을 지원하는 개\n"
          ]
        }
      ]
    }
  ]
}
